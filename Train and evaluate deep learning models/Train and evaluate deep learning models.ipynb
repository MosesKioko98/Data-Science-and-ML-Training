{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc80c7dd",
   "metadata": {},
   "source": [
    "## Train and evaluate deep learning models\n",
    "\n",
    "Deep learning is an advanced form of machine learning that emulates the way the human brain learns through networks of connected neurons.\n",
    "\n",
    "Associated with each x value is a weigh(w), which is used to strengthen or weaken the effect of the x value to simulate learning.\n",
    "\n",
    "Additionally, a bias(b) input is added to enable fine-grained control over the network.\n",
    "\n",
    "During the training process, thw **w** and **b** values will be adjusted to tune the network so that it \"learns\" to produce correct outupts.\n",
    "\n",
    "The neuron itself encapsualtes a function that calculates a weighted sum of **x,w, and b**. This function is in turn encosed in an activation function that constrains the results(often to a value between 0 and 1) to determine whether or not the neuron passes an output onto the next layer of nuerons in the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34807fd",
   "metadata": {},
   "source": [
    "### Deep neural network(DNN) concepts\n",
    "\n",
    "When you create a DNN model, you must define an input layer that supports the number of features your model will process , and an output layer that reflects the number of outputs you expect it to produce.\n",
    "\n",
    "You can decide how many hidden layers you want to include and how many neurons are in each of them; but you have no control over the input and output values for these layers- these are determined by the model training process.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef3457d",
   "metadata": {},
   "source": [
    "#### Train a deep neural network\n",
    "\n",
    "The training process for a deep neural network consists of multiple iterations, called **epochs**. \n",
    "\n",
    "For the first epoch,you start by assigning random initialization values for the weights(w) and bias(b) values. Then the process is as follows:\n",
    "\n",
    "1. Features for data observations with known values are submitted to the input layer. Generally, these observations are grouped into batches(often referred to as mini-batches)\n",
    "\n",
    "2. The neurons then apply thier function, and if activated, pass result onto the next layer until the output layer produces a prediction.\n",
    "\n",
    "3. The prediction is compared to the actual known value, and the amount of variance between the predicted and the true values(which we call the loss) is calculated.\n",
    "\n",
    "4. Based on the results,revised values for  the weights and bias values are calculated to reduce the loss, and this adjustments are **backpropagated** to the neurons in the network layers.\n",
    "\n",
    "5. The next epoch repeats the batch training forward pass with the revised weight and bias values, hopefully improving the accuracy of the model(by reducing the loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3c94c9",
   "metadata": {},
   "source": [
    "### A closer look at the loss function and backpropagation\n",
    "\n",
    "\n",
    "#### 1. Calculating loss\n",
    "#### 2. Optimizers\n",
    "The loss is calculated using a function, which operates on the results from the final layer of the network, which is also a function. The final layer of network operates on the outputs from the previos layers, which are also functions. So in effect, the entire model from the input layer right through to the loss calculation is just one big nested function. Functions have a few really useful characteristics, including:\n",
    "- You can conceptualize a function as a plotted line comparing the output with each of its variables.\n",
    "- You can use differential calculus to calculate the derivatives of the function at any point with respect to its variables\n",
    "\n",
    "We use **optimizer** to determine in which direction we need to adjust the weightd and bias (up or down) to reduce the overall amount of loss in the model.\n",
    "\n",
    "There are multiple commonly used optimization algorithmns:\n",
    "- stochastic gradient descent(SGD)\n",
    "- Adaptive Learning Rate(ADADELTA)\n",
    "- Adaptive Momentum Estimation(Adam)\n",
    "All are designed to figure out how to adjust the weights and biases to minimize loss\n",
    "\n",
    "#### 3. Learning rate\n",
    "The next question i, how much should the oprimizer adjust  the weights and bias value?\n",
    "\n",
    "The size of the adjustments is controlled by a parameter that you set training called the **learning rate**\n",
    "- A low learning rate results in small adjustments( so it can take more epochs to minimize the loss)\n",
    "- A high learning rate results in large adjustments(so you might miss the minimun altogether)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f07e8ae",
   "metadata": {},
   "source": [
    "### Deep Learning with TensorFlow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df10b362",
   "metadata": {},
   "source": [
    "#### Explore the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72226800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CulmenLength</th>\n",
       "      <th>CulmenDepth</th>\n",
       "      <th>FlipperLength</th>\n",
       "      <th>BodyMass</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>43.3</td>\n",
       "      <td>13.4</td>\n",
       "      <td>20.9</td>\n",
       "      <td>44.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>46.9</td>\n",
       "      <td>14.6</td>\n",
       "      <td>22.2</td>\n",
       "      <td>48.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>45.3</td>\n",
       "      <td>13.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>43.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>45.5</td>\n",
       "      <td>13.9</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>49.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>21.6</td>\n",
       "      <td>49.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>41.4</td>\n",
       "      <td>18.5</td>\n",
       "      <td>20.2</td>\n",
       "      <td>38.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>51.5</td>\n",
       "      <td>16.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>45.5</td>\n",
       "      <td>13.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>46.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>44.5</td>\n",
       "      <td>14.3</td>\n",
       "      <td>21.6</td>\n",
       "      <td>41.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>39.7</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>35.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CulmenLength  CulmenDepth  FlipperLength  BodyMass  Species\n",
       "160          43.3         13.4           20.9     44.00        1\n",
       "249          46.9         14.6           22.2     48.75        1\n",
       "194          45.3         13.7           21.0     43.00        1\n",
       "198          45.5         13.9           21.0     42.00        1\n",
       "248          49.4         15.8           21.6     49.25        1\n",
       "123          41.4         18.5           20.2     38.75        0\n",
       "265          51.5         16.3           23.0     55.00        1\n",
       "164          45.5         13.7           21.4     46.50        1\n",
       "178          44.5         14.3           21.6     41.00        1\n",
       "105          39.7         18.9           18.4     35.50        0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the training dataset (excluding rows with null values)\n",
    "penguins = pd.read_csv('penguins.csv').dropna()\n",
    "\n",
    "# we'll just rescale the FlipperLength and BodyMass so they're on a similar scale to the bill measurements\n",
    "penguins['FlipperLength'] = penguins['FlipperLength']/10\n",
    "penguins['BodyMass'] = penguins['BodyMass']/100\n",
    "\n",
    "# The dataset is too small to be useful for deep learning\n",
    "# So we'll oversample it to increase its size\n",
    "for i in range(1,3):\n",
    "    penguins = penguins.append(penguins)\n",
    "\n",
    "# Display a random sample of 10 observations\n",
    "sample = penguins.sample(10)\n",
    "sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e9d146",
   "metadata": {},
   "source": [
    "The Species column is the label our model will predict. Each label value represents a class of penguin species, encoded as 0, 1, or 2. The following code shows the actual species to which these class labels corrrespond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb4faee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CulmenLength' 'CulmenDepth' 'FlipperLength' 'BodyMass' 'Species'] SpeciesName\n",
      "[ 45.3 13.7 21.0 43.0 1 ] Gentoo\n",
      "[ 48.7 14.1 21.0 44.5 1 ] Gentoo\n",
      "[ 49.1 15.0 22.8 55.0 1 ] Gentoo\n",
      "[ 37.8 17.1 18.6 33.0 0 ] Adelie\n",
      "[ 46.0 18.9 19.5 41.5 2 ] Chinstrap\n",
      "[ 51.5 16.3 23.0 55.0 1 ] Gentoo\n",
      "[ 40.1 18.9 18.8 43.0 0 ] Adelie\n",
      "[ 46.4 15.6 22.1 50.0 1 ] Gentoo\n",
      "[ 42.8 18.5 19.5 42.5 0 ] Adelie\n",
      "[ 42.1 19.1 19.5 40.0 0 ] Adelie\n"
     ]
    }
   ],
   "source": [
    "penguin_classes = ['Adelie', 'Gentoo', 'Chinstrap']\n",
    "print(sample.columns[0:5].values, 'SpeciesName')\n",
    "for index, row in penguins.sample(10).iterrows():\n",
    "    print('[',row[0], row[1], row[2],row[3], int(row[4]), ']',penguin_classes[int(row[-1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcb7d60",
   "metadata": {},
   "source": [
    "As is common in a supervised learning problem, we'll split the dataset into a set of records with which to train the model, and a smaller set with which to validate the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb56c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: 957, Test Set: 411 \n",
      "\n",
      "Sample of features and labels:\n",
      "[51.1 16.5 22.5 52.5] 1 (Gentoo)\n",
      "[50.7 19.7 20.3 40.5] 2 (Chinstrap)\n",
      "[49.5 16.2 22.9 58. ] 1 (Gentoo)\n",
      "[39.3 20.6 19.  36.5] 0 (Adelie)\n",
      "[42.5 20.7 19.7 45. ] 0 (Adelie)\n",
      "[50.  15.3 22.  55.5] 1 (Gentoo)\n",
      "[50.2  18.7  19.8  37.75] 2 (Chinstrap)\n",
      "[50.7 19.7 20.3 40.5] 2 (Chinstrap)\n",
      "[49.1  14.5  21.2  46.25] 1 (Gentoo)\n",
      "[43.2 16.6 18.7 29. ] 2 (Chinstrap)\n",
      "[38.8  17.6  19.1  32.75] 0 (Adelie)\n",
      "[37.8 17.1 18.6 33. ] 0 (Adelie)\n",
      "[45.8 14.2 21.9 47. ] 1 (Gentoo)\n",
      "[43.8 13.9 20.8 43. ] 1 (Gentoo)\n",
      "[36.  17.1 18.7 37. ] 0 (Adelie)\n",
      "[43.3 13.4 20.9 44. ] 1 (Gentoo)\n",
      "[36.  18.5 18.6 31. ] 0 (Adelie)\n",
      "[41.1  19.   18.2  34.25] 0 (Adelie)\n",
      "[33.1 16.1 17.8 29. ] 0 (Adelie)\n",
      "[40.9 13.7 21.4 46.5] 1 (Gentoo)\n",
      "[45.2 17.8 19.8 39.5] 2 (Chinstrap)\n",
      "[48.4 14.6 21.3 58.5] 1 (Gentoo)\n",
      "[43.6 13.9 21.7 49. ] 1 (Gentoo)\n",
      "[38.5  17.9  19.   33.25] 0 (Adelie)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = ['CulmenLength','CulmenDepth','FlipperLength','BodyMass']\n",
    "label = 'Species'\n",
    "   \n",
    "# Split data 70%-30% into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(penguins[features].values,\n",
    "                                                    penguins[label].values,\n",
    "                                                    test_size=0.30,\n",
    "                                                    random_state=0)\n",
    "\n",
    "print ('Training Set: %d, Test Set: %d \\n' % (len(x_train), len(x_test)))\n",
    "print(\"Sample of features and labels:\")\n",
    "\n",
    "# Take a look at the first 25 training features and corresponding labels\n",
    "for n in range(0,24):\n",
    "    print(x_train[n], y_train[n], '(' + penguin_classes[y_train[n]] + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb96a7d8",
   "metadata": {},
   "source": [
    "The features are the measurements for each penguin observation, and the label is a numeric value that indicates the species of penguin that the observation represents (Adelie, Gentoo, or Chinstrap)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e85d2b",
   "metadata": {},
   "source": [
    "### Install and import TensorFlow libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0335a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n",
      "Keras version: 2.6.0\n",
      "TensorFlow version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "# pip install tensorflow\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Set random seed for reproducability\n",
    "tensorflow.random.set_seed(0)\n",
    "\n",
    "print(\"Libraries imported.\")\n",
    "print('Keras version:',keras.__version__)\n",
    "print('TensorFlow version:',tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822d42b6",
   "metadata": {},
   "source": [
    "### Prepare the data for TensorFlow\n",
    "\n",
    "We've already loaded our data and split it into training and validation datasets. However, we need to do some further data preparation so that our data will work correctly with TensorFlow. Specifically, we need to set the data type of our features to 32-bit floating point numbers, and specify that the labels represent categorical classes rather than numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eb6b67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready...\n"
     ]
    }
   ],
   "source": [
    "# Set data type for float features\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Set data types for categorical labels\n",
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = utils.to_categorical(y_test)\n",
    "print('Ready...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048372a0",
   "metadata": {},
   "source": [
    "### Define a neural network\n",
    "\n",
    "We'll create a network that consists of 3 fully-connected layers:\n",
    "- An input layer that receives an input value in each fearure (in this case, the four penguin measurements) and applies a RELU activation function.\n",
    "- A hidden layer that receives ten inputs and applies a RELU activation function.\n",
    "- An output layer that uses a SoftMax activation function to generate an output for penguin species(which represents the classification probabilities for each of the possible penguin species)\n",
    "**Softmax** functions produce a vector with probability values that sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "678f86c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define a classifier network\n",
    "h1 = 10 # Number of hidden layer nodes\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(h1,input_dim=len(features),activation='relu'))\n",
    "model.add(Dense(h1,input_dim=h1,activation='relu'))\n",
    "model.add(Dense(len(penguin_classes),input_dim=h1,activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df0559e",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "To train the model, we need to repeatedly feed the training values forward through the network, use a loss function to calculate the loss,use an optimizer to backpropagate the weight and bias value adjustments, and validate the model using the test data we withheld.\n",
    "\n",
    "To do this, we'll apply an **Adam optimizer** to a **categorical cross-entropy loss function** iteratively over 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceb46ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User-Pc\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96/96 [==============================] - 3s 10ms/step - loss: 23.8942 - accuracy: 0.1912 - val_loss: 11.2900 - val_accuracy: 0.2165\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 5.0865 - accuracy: 0.2142 - val_loss: 1.5626 - val_accuracy: 0.1752\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 1.2712 - accuracy: 0.2727 - val_loss: 1.1591 - val_accuracy: 0.3139\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 1.1068 - accuracy: 0.3814 - val_loss: 1.0832 - val_accuracy: 0.4453\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 1.0432 - accuracy: 0.4598 - val_loss: 1.0545 - val_accuracy: 0.4574\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 1.0258 - accuracy: 0.5183 - val_loss: 1.0425 - val_accuracy: 0.4842\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 1.0118 - accuracy: 0.5601 - val_loss: 1.0315 - val_accuracy: 0.5547\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 1.0008 - accuracy: 0.5998 - val_loss: 1.0189 - val_accuracy: 0.6156\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.9920 - accuracy: 0.6207 - val_loss: 1.0050 - val_accuracy: 0.6521\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.9762 - accuracy: 0.6667 - val_loss: 0.9911 - val_accuracy: 0.6618\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.9639 - accuracy: 0.6949 - val_loss: 0.9781 - val_accuracy: 0.6813\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.9394 - accuracy: 0.6803 - val_loss: 0.8758 - val_accuracy: 0.6350\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.7998 - accuracy: 0.7200 - val_loss: 0.7991 - val_accuracy: 0.7129\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.7341 - accuracy: 0.7450 - val_loss: 0.7380 - val_accuracy: 0.7202\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.6758 - accuracy: 0.7764 - val_loss: 0.6802 - val_accuracy: 0.7421\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.6188 - accuracy: 0.7847 - val_loss: 0.6292 - val_accuracy: 0.7470\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.5758 - accuracy: 0.7973 - val_loss: 0.5871 - val_accuracy: 0.7567\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7962 - val_loss: 0.5660 - val_accuracy: 0.7786\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.4958 - accuracy: 0.8297 - val_loss: 0.5272 - val_accuracy: 0.7786\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.8213 - val_loss: 0.4849 - val_accuracy: 0.7713\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.8318 - val_loss: 0.4676 - val_accuracy: 0.7640\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8422 - val_loss: 0.4518 - val_accuracy: 0.7689\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8527 - val_loss: 0.4383 - val_accuracy: 0.8054\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3711 - accuracy: 0.8662 - val_loss: 0.3915 - val_accuracy: 0.8224\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.8746 - val_loss: 0.3924 - val_accuracy: 0.8808\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.8934 - val_loss: 0.3521 - val_accuracy: 0.8710\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.9080 - val_loss: 0.3362 - val_accuracy: 0.8759\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.3006 - accuracy: 0.9195 - val_loss: 0.3216 - val_accuracy: 0.9002\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2822 - accuracy: 0.9310 - val_loss: 0.3074 - val_accuracy: 0.8929\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.2696 - accuracy: 0.9363 - val_loss: 0.2890 - val_accuracy: 0.9075\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.2539 - accuracy: 0.9446 - val_loss: 0.2870 - val_accuracy: 0.8662\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2422 - accuracy: 0.9394 - val_loss: 0.2752 - val_accuracy: 0.8832\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2292 - accuracy: 0.9457 - val_loss: 0.2491 - val_accuracy: 0.9148\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2142 - accuracy: 0.9509 - val_loss: 0.2343 - val_accuracy: 0.9367\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.2034 - accuracy: 0.9530 - val_loss: 0.2233 - val_accuracy: 0.9489\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1929 - accuracy: 0.9624 - val_loss: 0.2061 - val_accuracy: 0.9635\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1807 - accuracy: 0.9561 - val_loss: 0.2004 - val_accuracy: 0.9562\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1724 - accuracy: 0.9655 - val_loss: 0.1851 - val_accuracy: 0.9732\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1618 - accuracy: 0.9718 - val_loss: 0.1749 - val_accuracy: 0.9757\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1516 - accuracy: 0.9687 - val_loss: 0.1627 - val_accuracy: 0.9684\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9707 - val_loss: 0.1555 - val_accuracy: 0.9708\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1393 - accuracy: 0.9666 - val_loss: 0.1717 - val_accuracy: 0.9465\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1286 - accuracy: 0.9781 - val_loss: 0.1403 - val_accuracy: 0.9805\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1235 - accuracy: 0.9749 - val_loss: 0.1313 - val_accuracy: 0.9781\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1134 - accuracy: 0.9749 - val_loss: 0.1223 - val_accuracy: 0.9805\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1085 - accuracy: 0.9801 - val_loss: 0.1165 - val_accuracy: 0.9830\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1034 - accuracy: 0.9833 - val_loss: 0.1173 - val_accuracy: 0.9732\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0971 - accuracy: 0.9833 - val_loss: 0.1118 - val_accuracy: 0.9805\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0922 - accuracy: 0.9833 - val_loss: 0.1018 - val_accuracy: 0.9830\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0894 - accuracy: 0.9822 - val_loss: 0.1046 - val_accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters for optmizer\n",
    "learning_rate = 0.001\n",
    "opt = optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=opt,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# Train the model over 50 epochs using 10-observations batches and using the test holdout dataset for validation\n",
    "num_epochs = 50\n",
    "history = model.fit(x_train,y_train,epochs=num_epochs,batch_size = 10,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7669717",
   "metadata": {},
   "source": [
    "### Review training and validation loss\n",
    "\n",
    "Afte training is complete, we can examine the loss meric we recorded while training and validating the model.\n",
    "- The loss should reduce with each epoch, showing that the model is learning the right weights and biases to predict the correct labels\n",
    "- The training loss and validation loss should follow a similar trend, showing that the model is not **overfitting** to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5800deff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's plot the loss metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epoch_nums = range(1,num_epochs+1)\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "plt.plot(epoch_nums,training_loss)\n",
    "plt.plot(epoch_nums,validation_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training','validation'],loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aea99f",
   "metadata": {},
   "source": [
    "### View the learned weights and biases\n",
    "\n",
    "The trained model consists of the final-weights and biases that were determined by the optimizer during training. Based on our network model we should expect the following values for for each layer:\n",
    "\n",
    "- Layer 1: There are 4 input values going to ten output nodes, so there should be 4 x 10 weghts and 10 bias values\n",
    "- Layer 2: There are 10 input values going to 10 output nodes, so there should be 10 x 10 weights and 10 bias values.\n",
    "- Layer 3: There are ten input values going to three output nodes, so there should be 10 x 3 weights and 3 bias values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20a40c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Weights:\n",
      " [[-0.27236846 -0.3841947   0.03324002  0.08020484 -0.10909867  0.05677445\n",
      "  -0.19284698  0.8463785   0.35794353 -0.4905011 ]\n",
      " [ 0.27471453  0.21265197  0.08151422 -0.17707926 -0.10406601  0.8080873\n",
      "   0.34789598 -0.05428047 -0.607791   -0.5447268 ]\n",
      " [-0.28836262 -0.634329    0.2833845   0.34767175  0.23550075 -0.01212122\n",
      "   0.14559275 -0.797869   -0.5164289   0.3296095 ]\n",
      " [-0.42851955 -0.24623463 -0.28597653 -0.5230521  -0.43773973  0.3698575\n",
      "  -0.0764817   0.23638242  0.75253886 -0.4691702 ]] \n",
      "Biases [ 0.          0.         -0.01292539  0.          0.          0.20184621\n",
      " -0.19173315 -0.26134843 -0.31521472  0.        ]\n",
      "--------\n",
      "Weights:\n",
      " [[ 0.0607031  -0.30530828  0.39975524  0.3037489   0.15896738  0.03326017\n",
      "  -0.53190327  0.40915883 -0.03316814 -0.1240823 ]\n",
      " [ 0.42301047  0.14984506 -0.54566675  0.3919103  -0.4295466   0.50397205\n",
      "  -0.31616646  0.17803025 -0.41518384 -0.38429344]\n",
      " [ 0.5336163   0.37752342 -0.4694244   0.17206895 -0.04215616  0.5297911\n",
      "   0.43569058  0.28243893  0.26588047 -0.2233491 ]\n",
      " [-0.04491103  0.19579428 -0.26655364  0.17358297  0.3112036   0.53520477\n",
      "  -0.3109483  -0.5284722  -0.00098199 -0.44063687]\n",
      " [ 0.5135      0.39074183  0.39206952 -0.03048635  0.02663547  0.20555359\n",
      "   0.09307003  0.24590033 -0.49007446 -0.2917699 ]\n",
      " [ 0.5036509  -0.3901862   0.6040679   0.29417115 -0.26569188 -0.5313456\n",
      "   0.41427484 -0.15646037  0.00371231 -0.04586926]\n",
      " [ 0.26545775 -0.19090915  0.06543596 -0.30627972  0.12806404 -0.38203925\n",
      "  -0.2151853   0.41642922  0.2622466  -0.49726105]\n",
      " [-0.43842497 -0.21495155 -0.14270814 -0.46094683 -0.20800981  0.3025053\n",
      "  -0.01376547  0.40885383  0.27342087 -0.25861204]\n",
      " [-0.5077288  -0.4176368  -0.24631874 -0.49696004 -0.27225545 -0.38996994\n",
      "  -0.4083917   0.16560248 -0.26306093  0.2282074 ]\n",
      " [ 0.32320213 -0.30822456 -0.37115166  0.45703936 -0.35191107  0.24120325\n",
      "  -0.2000556   0.23292273 -0.33508268 -0.51532805]] \n",
      "Biases [-0.03101527  0.          0.43818402  0.          0.          0.\n",
      "  0.12236584 -0.29204667 -0.3032516  -0.0152769 ]\n",
      "--------\n",
      "Weights:\n",
      " [[-0.3835068   0.32607827 -0.04719007]\n",
      " [ 0.50995994 -0.12620813 -0.6595991 ]\n",
      " [ 0.53403324  0.02766322 -0.21622902]\n",
      " [ 0.54463303 -0.50025463  0.06109887]\n",
      " [ 0.26757038 -0.67376095 -0.18467396]\n",
      " [ 0.08888024 -0.2536324   0.20257705]\n",
      " [ 1.1713445  -1.5687052   0.6411079 ]\n",
      " [-0.4916396   0.3857358   0.19552365]\n",
      " [-0.5256169  -0.34712172  0.68313724]\n",
      " [ 0.6409571  -0.6129823  -0.03113725]] \n",
      "Biases [ 0.32175842  0.46051514 -0.49325743]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()[0]\n",
    "    biases = layer.get_weights()[1]\n",
    "    print('--------\\nWeights:\\n',weights,'\\nBiases',biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8044a5d7",
   "metadata": {},
   "source": [
    "### Evaluate model perfomance\n",
    "\n",
    "A common way to visualize the performance of a classification model is to create a confusion matrix that shows a crosstab of correct and incorrect predictions for each class.\n",
    "\n",
    "Tensorflow doesn't have a built-in confusion matrix metric, so we will use Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87137bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class_probabilities = model.predict(x_test)\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(penguin_classes))\n",
    "plt.xticks(tick_marks, penguin_classes, rotation=85)\n",
    "plt.yticks(tick_marks, penguin_classes)\n",
    "plt.xlabel(\"Predicted Species\")\n",
    "plt.ylabel(\"Actual Species\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdea21c",
   "metadata": {},
   "source": [
    "### Save the trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "625711f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved as, models/penguin-classifier.h5\n"
     ]
    }
   ],
   "source": [
    "modelFileName = 'models/penguin-classifier.h5'\n",
    "model.save(modelFileName)\n",
    "del model # deletes the existing model variable\n",
    "print('model saved as,',modelFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93443cda",
   "metadata": {},
   "source": [
    "#### Use the trained model\n",
    "\n",
    "When we have a new penguin observation, we can use the model to predict the species.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7a55669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample: [[50.4 15.3 20.  50. ]]\n",
      "Gentoo\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = models.load_model(modelFileName)\n",
    "\n",
    "# CReate a new array of features\n",
    "x_new = np.array([[50.4,15.3,20,50]])\n",
    "print ('New sample: {}'.format(x_new))\n",
    "\n",
    "# Use the model to predict the class\n",
    "class_probabilities = model.predict(x_new)\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "\n",
    "print(penguin_classes[predictions[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082b2d86",
   "metadata": {},
   "source": [
    "## Convolutional neural networks\n",
    "\n",
    "At hte heart of deep learning's success in this area is a kind of model called a **convolutional network or CNN**. A CNN typically works by extracting features from images,and then feeding those features into a fully connected neural network to generate a prediction. The feature extraction layers in the network have the effect of reducing the number of features from the potentially huge array of individuals pixel values to a smaller feature e that supports label prediction.\n",
    "\n",
    "### Layers in a CNN\n",
    "CNNs consists of multiple layers,each performing a specific task in extracting features or predicting labels.\n",
    "\n",
    "##### 1. Convolution layers\n",
    "It extracts important features in images. It works by applying a filter to images. The filter is defined by a **kernel** that consists of a matrix of weight values\n",
    "\n",
    "Because of the size of the filter kernel,we can't calculate values for the pixels at the adge;so we typically just apply a padding value(often 0)\n",
    "\n",
    "The output of the convolution is typically passed to an activation function,which is often a **Rectified Linear Unit** function that ensures negative values are set to 0\n",
    "The resulting matrix is a feature map of feature values that can be used to train a machine learnung model.\n",
    "\n",
    "Typically, a convolutional layer applies multiple filter kernels. Each  filter produces a different feature map, and all of the feature maps are passed onto the next layer of the network.\n",
    "\n",
    "##### 2. Pooling layers\n",
    "After extracting feature values from images, pooling (or downscaling) layers are used to reduce the number of feature values while retaining the key differentiating features that have been extracted.\n",
    "\n",
    "One of the most common kinds of pooling is **max poolong** in which a filter is applied to the image, and only the maximum pixel value within the filter area is retained.\n",
    "\n",
    "##### 3. Dropping layers\n",
    "One of the most common challenges in a CNN is the avaoidance of **overfitting**, where the resulting model performs well with the training data but doen't generalize well to new data on which it wasn't trained.\n",
    "\n",
    "One technique you can use to mitigate overfitting is to include layers in which the training process randomly eliminates(or \"drops\") feature maps. This may seem counterintuitive, but it's an effective way to ensure that the model doesn't learn to be over-dependent on the training images.\n",
    "\n",
    "Other techniques you can use to mitigate overfitting include randomly flipping, mirroring, or skewing the training images to generate data that varies between training epochs.\n",
    "\n",
    "##### 4. Flattening layers\n",
    "\n",
    "It is used to flatten the feature maps into a vector of values that can be used as input to a fully connected layer.\n",
    "\n",
    "##### 5. Fully connected layers\n",
    "\n",
    "Usually,a CNN ends with a fully connected network in which the feature values are passed into a layer, thruogh one or more hidden layers, and generate predicted values in an ouput layer.\n",
    "\n",
    "\n",
    "### Train a CNN model\n",
    "\n",
    "As with any deep neural network, a CNN is trained by passing batches of training data through it over multiple epochs,adjusting the weights and bias values based on the loss calculated for each epoch. In the case of a CNN, backpropagation of adjusted weights includes filter kernel weights used in convolutional layers as well as the weights usd in fully connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d85efc",
   "metadata": {},
   "source": [
    "### COnvolutional Neural Networks with TensorFlow\n",
    "\n",
    "\"Deep Learning\" is a general term that usually refers to the use of neural networks with multiple layers that synthesize the way the human brain learns and makes decisions. A convolutional neural network is a kind of neural network that extracts features from matrices of numeric values (often images) by convolving multiple filters over the matrix values to apply weights and identify patterns, such as edges, corners, and so on in an image. The numeric representations of these patterns are then passed to a fully-connected neural network layer to map the features to specific classes.\n",
    "\n",
    "There are several commonly used frameworks for creating CNNs. In this notebook, we'll build a simple example CNN using TensorFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12cb2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import and install libraries\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95518823",
   "metadata": {},
   "source": [
    "#### Explore the data\n",
    "In this exercise,we'll train a CNN-based classidication model that can classify images of geometric shapes.Let's take a look at the classes of shapes the model needs to identify"
   ]
  },
  {
   "cell_type": "raw",
   "id": "23476db4",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "# The images are in the data/shapes folder\n",
    "data_folder = pd.read_html('shapes.html')\n",
    "# get the class names\n",
    "classes = os.listdir(data_folder)\n",
    "classes.sort()\n",
    "print(len(classes),'classes:')\n",
    "print(classes)\n",
    "\n",
    "# Show the first image in each folder\n",
    "fig = plt.figure(figsize=(8,12))\n",
    "i = 0\n",
    "for sub_dir in os.listdir(data_folder):\n",
    "    i+=1\n",
    "    img_file = os.listdir(os.path.join(data_folder,sub_dir))[0]\n",
    "    img_path = os.path.join(data_folder, sub_dir, img_file)\n",
    "    img = mpimg.imread(img_path)\n",
    "    a=fig.add_subplot(1, len(classes),i)\n",
    "    a.axis('off')\n",
    "    imgplot = plt.imshow(img)\n",
    "    a.set_title(img_file)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc4728",
   "metadata": {},
   "source": [
    "### Prepare the data\n",
    "\n",
    "Before we can train the model, we need to prepare the data. We'll divide the feature values by 255 to normalize them as floating point values between 0 and 1, and we'll split the data so that we can use 70% of it to train the model, and hold back 30% to validate it. When loading the data, the data generator will assign \"hot-encoded\" numeric labels to indicate which class each image belongs to based on the subfolders in which the data is stored. In this case, there are three subfolders - circle, square, and triangle, so the labels will consist of three 0 or 1 values indicating which of these classes is associated with the image - for example the label [0 1 0] indicates that the image belongs to the second class (square).\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1286d0e",
   "metadata": {},
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "img_size = (128, 128)\n",
    "batch_size = 30\n",
    "\n",
    "print(\"Getting Data...\")\n",
    "datagen = ImageDataGenerator(rescale=1./255, # normalize pixel values\n",
    "                             validation_split=0.3) # hold back 30% of the images for validation\n",
    "\n",
    "print(\"Preparing training dataset...\")\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_folder,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training') # set as training data\n",
    "\n",
    "print(\"Preparing validation dataset...\")\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_folder,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # set as validation data\n",
    "\n",
    "classnames = list(train_generator.class_indices.keys())\n",
    "print('Data generators ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b20825",
   "metadata": {},
   "source": [
    "### Define the CNN\n",
    "\n",
    "Now we're ready to create our model. This involves defining the layers for our CNN, and compiling them for multi-class classification."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0995628",
   "metadata": {},
   "source": [
    "# Define a CNN classifier network\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "# Define the model as a sequence of layers\n",
    "model = Sequential()\n",
    "\n",
    "# The input layer accepts an image and applies a convolution that uses 32 6x6 filters and a rectified linear unit activation function\n",
    "model.add(Conv2D(32, (6, 6), input_shape=train_generator.image_shape, activation='relu'))\n",
    "\n",
    "# Next we'll add a max pooling layer with a 2x2 patch\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# We can add as many layers as we think necessary - here we'll add another convolution and max pooling layer\n",
    "model.add(Conv2D(32, (6, 6), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# And another set\n",
    "model.add(Conv2D(32, (6, 6), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# A dropout layer randomly drops some nodes to reduce inter-dependencies (which can cause over-fitting)\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Flatten the feature maps \n",
    "model.add(Flatten())\n",
    "\n",
    "# Generate a fully-connected output layer with a predicted probability for each class\n",
    "# (softmax ensures all probabilities sum to 1)\n",
    "model.add(Dense(train_generator.num_classes, activation='softmax'))\n",
    "\n",
    "# With the layers defined, we can now compile the model for categorical (multi-class) classification\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676b4f6c",
   "metadata": {},
   "source": [
    "#### Train the model\n",
    "With the layers of the CNN defined, we're ready to train the model using our image data. In the example below, we use 5 iterations (epochs) to train the model in 30-image batches, holding back 30% of the data for validation. After each epoch, the loss function measures the error (loss) in the model and adjusts the weights (which were randomly generated for the first iteration) to try to improve accuracy."
   ]
  },
  {
   "cell_type": "raw",
   "id": "08419012",
   "metadata": {},
   "source": [
    "# Train the model over 5 epochs using 30-image batches and using the validation holdout dataset for validation\n",
    "num_epochs = 5\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827539c",
   "metadata": {},
   "source": [
    "#### View the loss history\n",
    "\n",
    "We tracked average training and validation loss history for each epoch. We can plot these to verify that loss reduced as the model was trained, and to detect overfitting (which is indicated by a continued drop in training loss after validation loss has levelled out or started to increase)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee6ee51e",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "epoch_nums = range(1,num_epochs+1)\n",
    "training_loss = history.history[\"loss\"]\n",
    "validation_loss = history.history[\"val_loss\"]\n",
    "plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eca111c",
   "metadata": {},
   "source": [
    "#### Evaluate model performance\n",
    "\n",
    "We can see the final accuracy based on the test data, but typically we'll want to explore performance metrics in a little more depth. Let's plot a confusion matrix to see how well the model is predicting each class."
   ]
  },
  {
   "cell_type": "raw",
   "id": "793fa09c",
   "metadata": {},
   "source": [
    "# Tensorflow doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Generating predictions from validation data...\")\n",
    "# Get the image and label arrays for the first batch of validation data\n",
    "x_test = validation_generator[0][0]\n",
    "y_test = validation_generator[0][1]\n",
    "\n",
    "# Use the model to predict the class\n",
    "class_probabilities = model.predict(x_test)\n",
    "\n",
    "# The model returns a probability value for each class\n",
    "# The one with the highest probability is the predicted class\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "\n",
    "# The actual labels are hot encoded (e.g. [0 1 0], so get the one with the value 1\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classnames))\n",
    "plt.xticks(tick_marks, classnames, rotation=85)\n",
    "plt.yticks(tick_marks, classnames)\n",
    "plt.xlabel(\"Predicted Shape\")\n",
    "plt.ylabel(\"Actual Shape\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02ae57a",
   "metadata": {},
   "source": [
    "#### Save the Trained model\n",
    "\n",
    "Now that you've trained a working model, you can save it (including the trained weights) for use later."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb3012bc",
   "metadata": {},
   "source": [
    "# Save the trained model\n",
    "modelFileName = 'models/shape_classifier.h5'\n",
    "model.save(modelFileName)\n",
    "del model  # deletes the existing model variable\n",
    "print('model saved as', modelFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edfd485",
   "metadata": {},
   "source": [
    "#### Use the trained model\n",
    "\n",
    "When you have a new image, you can use the saved model to predict its class."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a9642d8",
   "metadata": {},
   "source": [
    "from tensorflow.keras import models\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Function to predict the class of an image\n",
    "def predict_image(classifier, image):\n",
    "    from tensorflow import convert_to_tensor\n",
    "    # The model expects a batch of images as input, so we'll create an array of 1 image\n",
    "    imgfeatures = image.reshape(1, image.shape[0], image.shape[1], image.shape[2])\n",
    "\n",
    "    # We need to format the input to match the training data\n",
    "    # The generator loaded the values as floating point numbers\n",
    "    # and normalized the pixel values, so...\n",
    "    imgfeatures = imgfeatures.astype('float32')\n",
    "    imgfeatures /= 255\n",
    "    \n",
    "    # Use the model to predict the image class\n",
    "    class_probabilities = classifier.predict(imgfeatures)\n",
    "    \n",
    "    # Find the class predictions with the highest predicted probability\n",
    "    index = int(np.argmax(class_probabilities, axis=1)[0])\n",
    "    return index\n",
    "\n",
    "# Function to create a random image (of a square, circle, or triangle)\n",
    "def create_image (size, shape):\n",
    "    from random import randint\n",
    "    import numpy as np\n",
    "    from PIL import Image, ImageDraw\n",
    "    \n",
    "    xy1 = randint(10,40)\n",
    "    xy2 = randint(60,100)\n",
    "    col = (randint(0,200), randint(0,200), randint(0,200))\n",
    "\n",
    "    img = Image.new(\"RGB\", size, (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    if shape == 'circle':\n",
    "        draw.ellipse([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    elif shape == 'triangle':\n",
    "        draw.polygon([(xy1,xy1), (xy2,xy2), (xy2,xy1)], fill=col)\n",
    "    else: # square\n",
    "        draw.rectangle([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    del draw\n",
    "    \n",
    "    return np.array(img)\n",
    "\n",
    "# Create a random test image\n",
    "classnames = os.listdir(os.path.join('data', 'shapes'))\n",
    "classnames.sort()\n",
    "img = create_image ((128,128), classnames[randint(0, len(classnames)-1)])\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "\n",
    "# Use the classifier to predict the class\n",
    "model = models.load_model(modelFileName) # loads the saved model\n",
    "class_idx = predict_image(model, img)\n",
    "print (classnames[class_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7012dad3",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa854141",
   "metadata": {},
   "source": [
    "Transfer Learning is a technique whwre you can take an existing trained model and re-use its feature extraction layers, replacing its final classification layer with a fully-connected layer trained on your own custom images.\n",
    "\n",
    "With this technique, your model benefits from the feature extraction training that was perfomed on the base model to buld a classification model for your own specific set of object classes.\n",
    "\n",
    "Fundamentally, a pre-trained model can be a great way to produce an effective classifier even when you have limited data with wgich to train it.\n",
    "\n",
    "We will see how to implement transer learning for a classification model using TensorFlow."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a15b431f",
   "metadata": {},
   "source": [
    "# import TensorFlow libraries\n",
    "\n",
    "import tensorflow\n",
    "from  tensorflow import keras\n",
    "print('TensorFlow version:',tensorflow.__version__)\n",
    "print('Keras version:',keras.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fefdb8f",
   "metadata": {},
   "source": [
    "#### Prepare the base model\n",
    "\n",
    "To use transer learning, we need a base model from which we can use the trained feature extracrion layers. \n",
    "\n",
    "The **resnet** model is an CNN-based image classifier that has been pre-trained using a huge dataset of 3-color channel images of 224x224 pixels"
   ]
  },
  {
   "cell_type": "raw",
   "id": "224e9c71",
   "metadata": {},
   "source": [
    "base_model = keras.applications.resnet.ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "print(base_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd1d13",
   "metadata": {},
   "source": [
    "### Prepare the image data\n",
    "\n",
    "The pretrained model has many layers,starting with a convolutional layer that starts the feature extracton process from image data.\n",
    "\n",
    "For feature extraction to work with our own images, we need to ensure that the image data we use to train our prediction layer has the same number of features(pixel values) as the images originally used to train the feature extraction layers, so we need data loaders for color images that are 224x224 pixel in size.\n",
    "\n",
    "Tensorflow includes functions for loading and transforming data. We'll use these to create a generator for training data, and a second generator for test data(which we'll use to validate the trained model). The loaders will transform the image data to match the format used to train the original resnet CNN model and normalize them."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3fa2773",
   "metadata": {},
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_folder = 'data/shapes'\n",
    "pretrained_size = (224,224)\n",
    "batch_size = 30\n",
    "\n",
    "print(\"Getting Data...\")\n",
    "datagen = ImageDataGenerator(rescale=1./255, # normalize pixel values\n",
    "                             validation_split=0.3) # hold back 30% of the images for validation\n",
    "\n",
    "print(\"Preparing training dataset...\")\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_folder,\n",
    "    target_size=pretrained_size, # resize to match model expected input\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training') # set as training data\n",
    "\n",
    "print(\"Preparing validation dataset...\")\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_folder,\n",
    "    target_size=pretrained_size, # resize to match model expected input\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # set as validation data\n",
    "\n",
    "classnames = list(train_generator.class_indices.keys())\n",
    "print(\"class names: \", classnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4125cbaa",
   "metadata": {},
   "source": [
    "#### Create a prediction layer\n",
    "\n",
    "We downloaded the complete renset model excluding its final prediction layer, so need to combine these layer with a fully-connected(dense) layer that takes the flattened outputs from the feature extraction layers and generates a prediction for each of our image classes.\n",
    "\n",
    "We also need to freeze the feature extraction layers to retain the trained weights. Then when we train the model using our images, only the final prediction layer will learn new weight and bias values - the pre-trained weights already learned for feature extraction will remain the same."
   ]
  },
  {
   "cell_type": "raw",
   "id": "16f97000",
   "metadata": {},
   "source": [
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "# Freeze the already-trained layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create prediction layer for classification of our images\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "prediction_layer = Dense(len(classnames), activation='softmax')(x) \n",
    "model = Model(inputs=base_model.input, outputs=prediction_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Now print the full model, which will include the layers of the base model plus the dense layer we added\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9082a092",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "With the layers of the CNN deined, we're ready to train it using our image data. The weights used in the feature extraction layers from the base resnet model will not be changed by the training, only the final dense layer that maps the features to our shape classes will be trained."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cba07b81",
   "metadata": {},
   "source": [
    "# Train the model over 3 epochs\n",
    "num_epochs = 3\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71b6b6c",
   "metadata": {},
   "source": [
    "### View the loss history\n",
    "\n",
    "We tracked average training and validation loss for each epoch. We can plot these to verify that the loss reduced over the training process and to detect **over-fitting which is indicated by a continued drop in training loss after validation loss has levelled out or started to increase**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ab83943",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "epoch_nums = range(1,num_epochs+1)\n",
    "training_loss = history.history[\"loss\"]\n",
    "validation_loss = history.history[\"val_loss\"]\n",
    "plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5496eefa",
   "metadata": {},
   "source": [
    "### Evaluate model performance\n",
    "\n",
    "We want to explore performance metrics in a little more depth. Let's plot a confusion matrix to see how well the model is predicting each class."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a12178e1",
   "metadata": {},
   "source": [
    "# Tensorflow doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Generating predictions from validation data...\")\n",
    "# Get the image and label arrays for the first batch of validation data\n",
    "x_test = validation_generator[0][0]\n",
    "y_test = validation_generator[0][1]\n",
    "\n",
    "# Use the model to predict the class\n",
    "class_probabilities = model.predict(x_test)\n",
    "\n",
    "# The model returns a probability value for each class\n",
    "# The one with the highest probability is the predicted class\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "\n",
    "# The actual labels are hot encoded (e.g. [0 1 0], so get the one with the value 1\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classnames))\n",
    "plt.xticks(tick_marks, classnames, rotation=85)\n",
    "plt.yticks(tick_marks, classnames)\n",
    "plt.xlabel(\"Predicted Shape\")\n",
    "plt.ylabel(\"Actual Shape\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3d18af",
   "metadata": {},
   "source": [
    "### Use the trained model\n",
    "\n",
    "We can now the model to predict the class of an image."
   ]
  },
  {
   "cell_type": "raw",
   "id": "351a4588",
   "metadata": {},
   "source": [
    "from tensorflow.keras import models\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Function to predict the class of an image\n",
    "def predict_image(classifier, image):\n",
    "    from tensorflow import convert_to_tensor\n",
    "    # The model expects a batch of images as input, so we'll create an array of 1 image\n",
    "    imgfeatures = image.reshape(1, image.shape[0], image.shape[1], image.shape[2])\n",
    "\n",
    "    # We need to format the input to match the training data\n",
    "    # The generator loaded the values as floating point numbers\n",
    "    # and normalized the pixel values, so...\n",
    "    imgfeatures = imgfeatures.astype('float32')\n",
    "    imgfeatures /= 255\n",
    "    \n",
    "    # Use the model to predict the image class\n",
    "    class_probabilities = classifier.predict(imgfeatures)\n",
    "    \n",
    "    # Find the class predictions with the highest predicted probability\n",
    "    index = int(np.argmax(class_probabilities, axis=1)[0])\n",
    "    return index\n",
    "\n",
    "# Function to create a random image (of a square, circle, or triangle)\n",
    "def create_image (size, shape):\n",
    "    from random import randint\n",
    "    import numpy as np\n",
    "    from PIL import Image, ImageDraw\n",
    "    \n",
    "    xy1 = randint(10,40)\n",
    "    xy2 = randint(60,100)\n",
    "    col = (randint(0,200), randint(0,200), randint(0,200))\n",
    "\n",
    "    img = Image.new(\"RGB\", size, (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    if shape == 'circle':\n",
    "        draw.ellipse([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    elif shape == 'triangle':\n",
    "        draw.polygon([(xy1,xy1), (xy2,xy2), (xy2,xy1)], fill=col)\n",
    "    else: # square\n",
    "        draw.rectangle([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    del draw\n",
    "    \n",
    "    return np.array(img)\n",
    "# Create a random test image\n",
    "classnames = os.listdir(os.path.join('data', 'shapes'))\n",
    "classnames.sort()\n",
    "img = create_image ((224,224), classnames[randint(0, len(classnames)-1)])\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "\n",
    "# Use the classifier to predict the class\n",
    "class_idx = predict_image(model, img)\n",
    "print (classnames[class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5fbaca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
